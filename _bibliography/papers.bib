---
---

@string{ccsc = {Consortium for Computing Sciences in Colleges NW,}}




@article{waterhouse2025reflective,
  author       = {Eric C. Waterhouse and Pelumi Abimbola and Ayodeji Ibitoye and Babafemi G. Sorinolu},
  title        = {Designing for Reflective Learning: A Voice-Based Assistant for Intentional LLM Use in Education},
  journal      = {Journal of Computing Sciences in Colleges},
  year         = {2025},
  month        = {oct},
  volume       = {41},
  number       = {1},
  pages        = {145--157},
  publisher    = {Consortium for Computing Sciences in Colleges},
  address      = {Evansville, IN, USA},
  issn         = {1937-4771},
  issue_date   = {October 2025},
  numpages     = {10},
  doi          = {10.5555/yyyyyyyy.xxxxxxx},
  url          = {https://example.com/paper.pdf},
  abstract     = {Advancements in AI are reshaping traditional educational practices, presenting both opportunities and challenges. Effective learning demands time, reflection, and active student engagement, beyond the pursuit of immediate results. However, the rapid feedback from large language models (LLMs) risks encouraging surface-level learning and student dependency. This study examines the ethical implications of LLM use in education and proposes a framework for their intentional and controlled integration. We present a voice assistant powered by an LLM and deployed on a Raspberry Pi, designed to foster reflective, voice-based interactions that preserve opportunities for deep learning while harnessing LLM capabilities. This approach aims to support ethical, dependable, and pedagogically sound human-AI interactions. We anticipate that this tool will encourage student reflection and contribute to more deliberate and meaningful engagement with AI in educational contexts.}
}


@inproceedings{onifade2019improved,
  title={Improved trust worthiness in electrical energy management using K-means augmented blockchain technology},
  author={Onifade, O and Sorinolu, B and Ibitoye, A},
  booktitle={3rd Biennial Conference on Transition from Observation to Knowledge to Intelligence},
  year={2019},
  abstract={The goal of an energy management organization aside from provision of value
added services is to generate profit. A widespread perception of unfairness and mistrust
regarding electricity distribution and billing method however exist among consumers in
several resource-constrained settings like Nigeria. In order to address this perceived
notion of unsatisfactory service deliver as well as enhance customer confidence, this study
was carried out primarily to create a reliable and efficient smart grid system for energy
management using a transparent, secured blockchain technology with K-Means algorithm.
The result is a tamper-proof system that ensures accurate storage of record of energy
dispensed from the grid and energy used by each consumer before the entire users are
then assigned into a four-clustered pattern of electricity usage.},
  url       = {https://www.researchgate.net/publication/336146122_Improved_Trust_Worthiness_in_Electrical_Energy_Management_Using_K-Means_Augmented_Blockchain_Technology}
}

@INPROCEEDINGS{9982740,
  author={Oyeleke, Richard O. and Sorinolu, Babafemi G.},
  booktitle={2022 IEEE International Conference on E-health Networking, Application & Services (HealthCom)}, 
  title={Towards Explainability in mHealth Application for Mitigation of Forward Head Posture in Smartphone Users}, 
  year={2022},
  volume={},
  number={},
  pages={49-55},
  keywords={Visualization;Head;Machine learning algorithms;Medical services;Predictive models;Prediction algorithms;Magnetic heads;Explainable AI;mHealth;smartphone;forward head posture;efficientNet CNN;physiatry},
  doi={10.1109/HealthCom54947.2022.9982740},
  abstract={Machine learning (ML) algorithms have recorded tremendous successes in many areas, notably healthcare. With increasing computing power of mobile devices, mobile health (mHealth) applications are embedded with ML models to learn users behavior and influence positive lifestyle changes. Although ML algorithms have shown impressive predictive power over the years, nonetheless, it is necessary that their inferences and recommendations are also explainable. Explainability can promote users’ trust, particularly when ML algorithms are deployed in high-stake domains such as healthcare. In this study, first, we present our proposed situation-aware mobile application called Smarttens coach app that we developed to assist smartphone users in mitigating forward head posture. It embeds an efficientNet CNN model to predict forward head posture in smartphone users by analyzing head posture images of the users. Our Smarttens coach app achieved a state-of-the-art accuracy score of 0.99. However, accuracy score alone does not tell users the whole story about how Smarttens coach app draws its inference on predicted posture binary class. This lack of explanation to justify the predicted posture class label could negatively impact users’ trust in the efficacy of the app. Therefore, we further validated our Smarttens coach app posture prediction efficacy by leveraging an explainable AI (XAI) framework called LIME to generate visual explanations for users’ predicted head posture class label.}
  }

